# used by hliang

# check job status
qstat -u hliang -r -ne | less

# Sum a single column in awk
awk '{sum+=$1}END{print sum}' < listTopScores.txt

# awk using multiple field separators
awk -F "=| "    # 2 separators: space and =
awk -F "[= ]"   # same
BEGIN { FS="[/() \"]" } # 5 separaters: / ( ) space "



MIRA
How would one set a minimum read length of 80 and a base default quality of 10 for 454 reads, but for Solexa reads a minimum read length of 30 with a base default quality of 15? The answer:

mira -job=denovo,genome,draft,454,solexa  -fasta
  454_SETTINGS -AS:mrl=80:bdq=10 SOLEXA_SETTINGS -AS:mrl=30:bdq=15

Notice the ..._SETTINGS section in the command line (or parameter file): these tell mira that all the following parameters until the advent of another switch are to be set specifically for the said technology.


## tar pipe to ssh/scp
tar zcvf - /wwwdata | ssh root@dumpserver.nixcraft.in "cat > /backup/wwwdata.tar.gz"
# OR
tar zcvf - /wwwdata | ssh root@192.168.1.201 "cat > /backup/wwwdata.tar.gz"
# OR
tar czf - /path/files-to-copy | ssh user@remotehost "cat > /path/data.tgz" 
# whole folder
tar zcvf - SOURCEDIR | ssh user@remotehost "(cd DESTDIR; tar zxvf -)"
# tar files in a list
tar cvf - -T files.list | ssh user@remotehost 'cd /dest/dir ; tar xvf -'


# You can restore tar backup over ssh session:
ssh root@192.168.1.201 "cat /backup/wwwdata.tar.gz" | tar zxvf -

# Equivalent to unix “less” command within R console
# page() which displays a representation of an object in a pager, like less.
dat <- data.frame(matrix(rnorm(1000), ncol = 10))
page(dat, method = "print")

# print 5 consecutive lines after a pattern in file using awk
awk '/PATTERN/ {for(i=1; i<=5; i++) {getline; print}}' inputfile
# or
awk '{ if (lines > 0) { print; --lines; } } /PATTERN/ { lines = 5 }' inputfile

# Count bases in a fasta file
grep -v '>' file.fasta | wc -m

# Converting FASTQ to FASTA with SED
# !!! assuming that each read entry occupies exactly 4 lines in the FASTQ file !!!
sed -n '1~4s/^@/>/p; 2~4p' 
# -n means only explicitly printed lines are included in output.
# 1~4 means select every 4th line, beginning at line 1. 


# get the unmapped reads from a bam file:
samtools view -f 4 file.bam > unmapped.sam

# get only the mapped reads. option '-F' works like -v of grep and skips the alignments for a specific flag.
samtools view -b -F 4 file.bam > mapped.bam

# extract only the first read from paired end bam files
samtools view -h -f 0x0040 test.bam > test_first_pair.sam
# extract only the second read from paired end bam files
samtools view -h -f 0x0080 test.bam > test_second_pair.sam

Flag	Chr	Description
0x0001	p	the read is paired in sequencing
0x0002	P	the read is mapped in a proper pair
0x0004	u	the query sequence itself is unmapped
0x0008	U	the mate is unmapped
0x0010	r	strand of the query (1 for reverse)
0x0020	R	strand of the mate
0x0040	1	the read is the first read in a pair
0x0080	2	the read is the second read in a pair
0x0100	s	the alignment is not primary
0x0200	f	the read fails platform/vendor quality checks
0x0400	d	the read is either a PCR or an optical duplicate

# strip html/xml tags
sed 's/<[^>]\+>//g'
# or 
sed 's/<[^<>]*>//g'

# split one fasta seq file in to mulitple smaller files, each has certain number of seq.
# e.g. each file has 10 seq:
cat input.fa | awk 'BEGIN {n_seq=0; seqperfile=10} (/^>/){n_seq++; if(n_seq%seqperfile==1){file=sprintf("output_split_%d_to_%d.fa",n_seq, n_seq+seqperfile-1)}} { print >> file } '

# install python packages (withou root permission) in specified folder
easy_install-python2.7 --prefix '/homes/hliang/local' scipy

# remote blast, search ncbi database
blastx -query in.fasta -db nr -remote -outfmt 5 -evalue 1e-3 -max_target_seqs 25 -out out.blastx.xml

# awk one-liner to extract a list of sequences from fasta file(s)
awk '(NR==FNR){id[">"$1]++} /^>/{inlist=(($1 in id)?1:0)} inlist{print}' some_ids.list input_seq.fasta > output_some_seq.fasta

# wget – recursively download all files from certain directory listed by apache
# Case: recursively download all the files that are in the ‘ddd’  folder for the url ‘http://hostname/aaa/bbb/ccc/ddd/&#8217;
# Solution:
wget -r -np -nH --cut-dirs=3 -R index.html http://hostname/aaa/bbb/ccc/ddd/
# Explanation:
# It will download all files and subfolders in ddd directory:
# recursively (-r),
# not going to upper directories, like ccc/… (-np, --no-parent),
# not saving files to hostname folder (-nH, --no-host-directories),
# but to ddd by omitting first 3 folders aaa, bbb, ccc (--cut-dirs=3),
# excluding index.html files (-R index.html, --reject rejlist)
